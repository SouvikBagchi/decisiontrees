<h3>This repository contains the following implementations of a very popular machine learning technique called the Decision Tree :</h3>
<h4>`ID3'</h4>
<h5>The ID3 algorithm uses _information gain_ as a criteria to measure the strength of an attribute for the target classification.</h5>

<h6>To understand information gain we need to define entropy first 

	Entropy (S) = - p<sub>+</sub> log<sub>2</sub> p<sub>+</sub> - p<sub>-</sub> log<sub>2</sub> p<sub>-</sub>

	Where p<sub>+</sub> is the proportion of the positive examples and p<sub>-</sub> is the proportion of negative examples

	Entropy in a more general form is defined as -

	Entropy(S) = \sum - p<sub>i</sub> log<sub>2</sub> p<sub>i</sub>

	

</h6>

